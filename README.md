# toxic-comments-detector

## Структура проекта
```
├── data # Используемые данные
│
├── dev # Набор констант и утилит для разработки
│   ├── constants
|   └── utils
│
├── models # различные модели для решения главной задачи классификации  
│
├── publishPackageUtils # инструменты для публикации пакета
│    
├── textPreprocessing # набор утилит для предобработки русскоязычных текстов
│   ├── text_utils # набор маленьких утилит по очистке текста
│   └── preprocess_text.py # собирает все утилиты из text_utils в одну функцию
│
└── wordEmbeddingsLayers # различные способы векторизации слов
```

## Навигация по проекту
- [Используемые данные](/data)
- [Предварительная очистка текстовых данных](/textPreprocessing)<br>
Как обрабатывались сырые текстовые данные перед их дальнейшим использованием в построении моделей машинного обучения.
- [Какие способы векторизации слов применялись](/wordEmbeddingsLayers)
- [Какие модели ML были опробованы для решения поставленной главной задачи классификации](/models)
- [Как опубликовать новую версию python-пакета](/publishPackageUtils/how-publish-package-instruction.md)